{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de archivos excel a la base de datos con python\n",
    "Se descargan todas las dependencias necesarias para leer los archivos CSV, XLSX y hacer la conexión con la base de datos en MySQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymysql\n",
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez descargadas, se importan para:\n",
    "- 1. Leer archivos csv a través de la libería que provee Python de forma natural (tomese en cuenta que este Jupyter Notebook se corre en Python 3.10.2)\n",
    "- 2. Realizar la conexión y las operaciones de escritura dentro de la base de datos en MySQL.\n",
    "- 3. Leer archivos Excel con extensión xlsx con la librería Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pymysql\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación,se explica paso a paso el procesamiento de los archivos para llenar la base de datos.\n",
    "\n",
    "Se define una función que contiene la conexión a la base de datos (host, puerto, usuario, contraseña y nombre de la base de datos), esto con el fin de que, si se migra a otro lado o cambian las variables de conexión, se pueda hacer el cambio más rápido, sin ir buscando la línea de conexión dentro de los procesamientos de los archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection_mysql():\n",
    "    conn = pymysql.connect(host=\"localhost\", port=3306, user=\"root\", passwd=\"\", db=\"weather\")\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definida la conexión (y el objeto `cursor` que permite la interacción), con `csv` se lee el archivo *stations.csv*, se itera en los registros y a su vez se va insertando en la base por medio de `commit()` ya que, por si sola la instrucción no se ejecuta, en caso de fallar, se realiza un `rollback()` para que no se ejecute la consulta, cuando termina de registrar se cierra la conexión a la base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se abre el archivo csv de las estaciones\n",
    "with open('../data/stations.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    #se inicia la conexion con MySQL\n",
    "    conn = connection_mysql()\n",
    "    cur = conn.cursor()\n",
    "    #conforme se va leyendo las lineas del archivo, se van insertando en la base de datos\n",
    "    for row in reader:\n",
    "        sql = \"INSERT INTO `stations` (`station_id`, `name`,`latitude`,`longitude`,`elevation`) VALUES (%s, %s,%s,%s,%s)\"\n",
    "        try:\n",
    "            cur.execute(sql, (row['station_id'],row['name'],row['latitude'],row['longitude'],row['elevation']))\n",
    "            conn.commit()\n",
    "            print(\"Record was successfully\")\n",
    "        except:\n",
    "            conn.rollback()\n",
    "            print(\"Record was failed\")\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se repite la misma acción para el archivo *variables.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se abre el archivo csv de las variables\n",
    "with open('../data/variables.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    #se inicia la conexion con MySQL\n",
    "    conn = connection_mysql()\n",
    "    cur = conn.cursor()\n",
    "    #conforme se va leyendo las lineas del archivo, se van insertando en la base de datos\n",
    "    for row in reader:\n",
    "        sql = \"INSERT INTO `variables` (`variable_id`, `name`, `description`, `units`) VALUES (%s, %s,%s,%s)\"\n",
    "        try:\n",
    "            cur.execute(sql, (row['variable_id'],row['name'],row['description'],row['units']))\n",
    "            conn.commit()\n",
    "            print(\"Record was successfully\")\n",
    "        except:\n",
    "            conn.rollback()\n",
    "            print(\"Record was failed\")\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se usa `pandas` para la lectura de los archivos Excel.\n",
    "Existen 5 variables que son cada una de las estaciones con sus respectivos archivos de observaciones de los años *2019*, *2020* y *2021* que se encuentran en una carpeta dentro del repositorio. Se trabaja una función que permite leer el archivo indicando donde se encuentran las columnas con los datos (segunda fila del archivo) debido a que cuando este se genera, toma la primera fila para poner el nombre de la tabla.\n",
    "\n",
    "Una vez cargado el archivo, se limpia de celdas vacías sin modificarlo y se procede a realizar las inserciones en la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File  ../step3/station2/2019.xlsx  was uploaded successfully\n",
      "File  ../step3/station2/2020.xlsx  was uploaded successfully\n",
      "File  ../step3/station2/2021.xlsx  was uploaded successfully\n",
      "File  ../step3/station3/2019.xlsx  was uploaded successfully\n",
      "File  ../step3/station3/2020.xlsx  was uploaded successfully\n",
      "File  ../step3/station3/2021.xlsx  was uploaded successfully\n",
      "File  ../step3/station4/2019.xlsx  was uploaded successfully\n",
      "File  ../step3/station4/2020.xlsx  was uploaded successfully\n",
      "File  ../step3/station4/2021.xlsx  was uploaded successfully\n",
      "File  ../step3/station5/2019.xlsx  was uploaded successfully\n",
      "File  ../step3/station5/2020.xlsx  was uploaded successfully\n",
      "File  ../step3/station5/2021.xlsx  was uploaded successfully\n"
     ]
    }
   ],
   "source": [
    "#se definen las direcciones de los archivos\n",
    "station1 = [\"../step3/station1/2019.xlsx\",\"../step3/station1/2020.xlsx\",\"../step3/station1/2021.xlsx\"]\n",
    "station2 = [\"../step3/station2/2019.xlsx\",\"../step3/station2/2020.xlsx\",\"../step3/station2/2021.xlsx\"]\n",
    "station3 = [\"../step3/station3/2019.xlsx\",\"../step3/station3/2020.xlsx\",\"../step3/station3/2021.xlsx\"]\n",
    "station4 = [\"../step3/station4/2019.xlsx\",\"../step3/station4/2020.xlsx\",\"../step3/station4/2021.xlsx\"]\n",
    "station5 = [\"../step3/station5/2019.xlsx\",\"../step3/station5/2020.xlsx\",\"../step3/station5/2021.xlsx\"]\n",
    "\n",
    "def insert_records(station,paths):\n",
    "    tam = len(paths)\n",
    "    if tam > 0:\n",
    "        for path in paths:       \n",
    "            #se define el header a partir de la segunda fila, debido a que en la primera está el titulo del documento\n",
    "            df = pd.read_excel(path,header=1)\n",
    "            #Limpia la data de celdas vacias sin alterarla, después se manejan las columnas por separado para poder\n",
    "            #procesar los registros de cada excel\n",
    "            new_df = df.dropna()\n",
    "            column_dates = new_df.columns[0]\n",
    "            column_grades=new_df.columns[1]\n",
    "            #se llama a la conexion de mysql\n",
    "            conn = connection_mysql()\n",
    "            cur = conn.cursor()\n",
    "            #se iteran en los registros del excel en turno\n",
    "            for index, row in new_df.iterrows():\n",
    "                sql_observation = \"INSERT INTO `observations` (`sensor_id`,`variable_id`, `observation_date`, `observed_value`, `status`) VALUES (%s,%s, %s,%s,%s)\"\n",
    "                try:\n",
    "                    cur.execute(sql_observation, (station,\"tmax\",row[column_dates],row[column_grades],\"\"))\n",
    "                    conn.commit()\n",
    "                    #print(\"Query success\")\n",
    "                except:\n",
    "                    conn.rollback()\n",
    "                    #print(\"Query fail\")\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "            print(\"File \",path,\" was uploaded successfully\")\n",
    "    else:\n",
    "        print(\"Array is not found\")\n",
    "\n",
    "insert_records(1,station1)\n",
    "insert_records(2,station2)\n",
    "insert_records(3,station3)\n",
    "insert_records(4,station4)\n",
    "insert_records(5,station5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b2db6ef3fb272424a50aaee9e5e8a93744fc8cbc5491064c8fffc3fa4a0316f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
